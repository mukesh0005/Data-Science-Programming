{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Import and install python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy and pandas libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "import summarytools\n",
    "from summarytools import dfSummary\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/Rscores_X_train.csv\")\n",
    "X_test = pd.read_csv(\"./data/Rscores_X_test.csv\")\n",
    "y_train = pd.read_csv(\"./data/Rscores_y_train.csv\")\n",
    "y_test = pd.read_csv(\"./data/Rscores_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none',max_iter=2000)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  Accuracy  Precision    Recall        F1\n",
       "0  default logistic  0.827586   0.839286  0.979167  0.903846"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randome search - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 4 candidates, totalling 60 fits\n",
      "The best precision_macro score is 0.3455509705431804\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "#random search in log\n",
    "score_measure = \"precision_macro\"\n",
    "kfolds = 15\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['liblinear']\n",
    "    \n",
    "}\n",
    "\n",
    "logreg_rand = LogisticRegression()\n",
    "\n",
    "rand_search_log = RandomizedSearchCV(estimator = logreg_rand, param_distributions=param_grid, cv=kfolds, n_iter=4,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search_log.fit(X_train,np.ravel(y_train,order='C'))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search_log.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search_log.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = rand_search_log.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rand_search_log_l2\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best macro-averaged precision score is 0.36766437367434\n",
      "... with parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision_macro\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "logreg_grid = LogisticRegression()\n",
    "grid_search_log = GridSearchCV(logreg_grid, param_grid=param_grid, cv=kfolds, \n",
    "                               scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                               return_train_score=True, error_score='raise')\n",
    "\n",
    "_ = grid_search_log.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best macro-averaged precision score is {grid_search_log.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_log.best_params_}\")\n",
    "\n",
    "bestLogReg = grid_search_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid_search_log.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"grid_search_log_l1\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm with linear kernel\n",
    "svm_lin_model = SVC(kernel=\"linear\",probability=True)\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"lin svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "The best precision_macro score is 0.4075079575468171\n",
      "... with parameters: {'C': 3.730229437354635, 'gamma': 0.12812444792935673, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "#random search in SVM\n",
    "from scipy.stats import uniform\n",
    "score_measure = \"precision_macro\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'kernel':['linear'],\n",
    "    'C': uniform(loc=0, scale=4),\n",
    "    'gamma': uniform(loc=0, scale=1)\n",
    "    \n",
    "}\n",
    "\n",
    "SVM_R_out = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = SVM_R_out, param_distributions=param_grid, cv=kfolds, n_iter=4,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0       rand_poly_svm  0.797980   0.814433  0.975309  0.887640"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = rand_search.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rand_poly_svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "#grid search in SVM\n",
    "score_measure = \"precision_macro\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,100],\n",
    "    'gamma':[1,0.1,0.01,0.001],\n",
    "    'kernel':['poly']\n",
    "    \n",
    "}\n",
    "\n",
    "SVM_G_out = SVC()\n",
    "grid_search = GridSearchCV(estimator = SVM_G_out, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = grid_search.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"grid_poly_svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()\n",
    "_ = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0       rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0               dtree  0.994595   0.993056  1.000000  0.996516"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = dtree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"dtree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTree Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best precision_macro score is 0.9737313755412134\n",
      "... with parameters: {'min_samples_split': 4, 'min_samples_leaf': 3, 'max_leaf_nodes': 34, 'max_depth': 36, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#random with tree\n",
    "score_measure = \"precision_macro\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(2,42),  \n",
    "    'min_samples_leaf': np.arange(2,42),\n",
    "    'max_leaf_nodes': np.arange(5, 42), \n",
    "    'max_depth': np.arange(2,42), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search_tree = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    " \n",
    "_ = rand_search_tree.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search_tree.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search_tree.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0       rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0               dtree  0.994595   0.993056  1.000000  0.996516\n",
       "0      rand_poly_tree  0.994565   0.993007  1.000000  0.996491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = rand_search_tree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rand_poly_tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dtree with Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "The best precision_macro score is 0.9753981515046645\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 39, 'max_leaf_nodes': 37, 'min_impurity_decrease': 0.0009, 'min_samples_leaf': 3, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "#grid with tree\n",
    "score_measure = \"precision_macro\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(3,6),  \n",
    "    'min_samples_leaf': np.arange(3,6),\n",
    "    'min_impurity_decrease': np.arange(0.0009, 0.0012,0.0001),\n",
    "    'max_leaf_nodes': np.arange(36,40), \n",
    "    'max_depth': np.arange(39,42), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search_tree = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_tree.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_tree.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0       rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0               dtree  0.994595   0.993056  1.000000  0.996516\n",
       "0      rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0     grid_poly_dtree  0.994565   0.993007  1.000000  0.996491"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid_search_tree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"grid_poly_dtree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), activation='relu',solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN-60,50,40</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  Accuracy  Precision    Recall        F1\n",
       "0    default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0  rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0  grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0             lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0       rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0               dtree  0.994595   0.993056  1.000000  0.996516\n",
       "0      rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0     grid_poly_dtree  0.994565   0.993007  1.000000  0.996491\n",
       "0         NN-60,50,40  0.994565   0.993007  1.000000  0.996491"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid_search_tree.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"NN-60,50,40\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(14))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(400, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 54ms/step - loss: 40.5125 - accuracy: 0.3426 - val_loss: 9.2056 - val_accuracy: 0.4932\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.2070 - accuracy: 0.3735 - val_loss: 1.2963 - val_accuracy: 0.4589\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2158 - accuracy: 0.4162 - val_loss: 1.0609 - val_accuracy: 0.4932\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1086 - accuracy: 0.4574 - val_loss: 1.1202 - val_accuracy: 0.4281\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0587 - accuracy: 0.4765 - val_loss: 1.1191 - val_accuracy: 0.3801\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0593 - accuracy: 0.4588 - val_loss: 1.0836 - val_accuracy: 0.4281\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0384 - accuracy: 0.4441 - val_loss: 0.9970 - val_accuracy: 0.5068\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0192 - accuracy: 0.4779 - val_loss: 1.0284 - val_accuracy: 0.4110\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0069 - accuracy: 0.4632 - val_loss: 1.0548 - val_accuracy: 0.3493\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9948 - accuracy: 0.4765 - val_loss: 0.9984 - val_accuracy: 0.4863\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9770 - accuracy: 0.5000 - val_loss: 1.0330 - val_accuracy: 0.4144\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9642 - accuracy: 0.5000 - val_loss: 1.0103 - val_accuracy: 0.4384\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9814 - accuracy: 0.4765 - val_loss: 1.0029 - val_accuracy: 0.5068\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9594 - accuracy: 0.5000 - val_loss: 1.0184 - val_accuracy: 0.4760\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9419 - accuracy: 0.5000 - val_loss: 1.0091 - val_accuracy: 0.4521\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9292 - accuracy: 0.5176 - val_loss: 1.0159 - val_accuracy: 0.5137\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9339 - accuracy: 0.5059 - val_loss: 1.0105 - val_accuracy: 0.5205\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9211 - accuracy: 0.5441 - val_loss: 1.0018 - val_accuracy: 0.4692\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9021 - accuracy: 0.5574 - val_loss: 1.0045 - val_accuracy: 0.5411\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8891 - accuracy: 0.5235 - val_loss: 0.9899 - val_accuracy: 0.5068\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9361 - accuracy: 0.5044 - val_loss: 0.9976 - val_accuracy: 0.5445\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9251 - accuracy: 0.5103 - val_loss: 1.0066 - val_accuracy: 0.4760\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9119 - accuracy: 0.5353 - val_loss: 1.0351 - val_accuracy: 0.4966\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9016 - accuracy: 0.5485 - val_loss: 0.9793 - val_accuracy: 0.4863\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.5338 - val_loss: 1.0156 - val_accuracy: 0.5103\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9298 - accuracy: 0.5294 - val_loss: 1.0592 - val_accuracy: 0.4863\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9528 - accuracy: 0.5265 - val_loss: 1.0409 - val_accuracy: 0.4486\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9466 - accuracy: 0.5250 - val_loss: 0.9640 - val_accuracy: 0.5377\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9163 - accuracy: 0.5647 - val_loss: 1.0126 - val_accuracy: 0.4863\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9033 - accuracy: 0.5471 - val_loss: 0.9867 - val_accuracy: 0.4897\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8791 - accuracy: 0.5676 - val_loss: 0.9175 - val_accuracy: 0.5205\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8572 - accuracy: 0.5824 - val_loss: 1.0343 - val_accuracy: 0.4418\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8982 - accuracy: 0.5471 - val_loss: 0.9729 - val_accuracy: 0.5240\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8685 - accuracy: 0.5721 - val_loss: 0.9403 - val_accuracy: 0.5719\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8499 - accuracy: 0.6029 - val_loss: 0.9253 - val_accuracy: 0.5616\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8183 - accuracy: 0.6059 - val_loss: 0.9341 - val_accuracy: 0.5205\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7715 - accuracy: 0.6074 - val_loss: 0.9895 - val_accuracy: 0.5205\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7754 - accuracy: 0.6324 - val_loss: 0.9616 - val_accuracy: 0.5479\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.7327 - accuracy: 0.6426 - val_loss: 0.8780 - val_accuracy: 0.5342\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7678 - accuracy: 0.6309 - val_loss: 1.1028 - val_accuracy: 0.3322\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8853 - accuracy: 0.5544 - val_loss: 1.1947 - val_accuracy: 0.4110\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9840 - accuracy: 0.5662 - val_loss: 1.0433 - val_accuracy: 0.4623\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8567 - accuracy: 0.5853 - val_loss: 0.9155 - val_accuracy: 0.5685\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8055 - accuracy: 0.6000 - val_loss: 0.8652 - val_accuracy: 0.5822\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7833 - accuracy: 0.6250 - val_loss: 0.8869 - val_accuracy: 0.5822\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7909 - accuracy: 0.6162 - val_loss: 0.9197 - val_accuracy: 0.5651\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7524 - accuracy: 0.6294 - val_loss: 0.8859 - val_accuracy: 0.5205\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7485 - accuracy: 0.6382 - val_loss: 0.9038 - val_accuracy: 0.5548\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7432 - accuracy: 0.6324 - val_loss: 0.9054 - val_accuracy: 0.5548\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7597 - accuracy: 0.6309 - val_loss: 0.8358 - val_accuracy: 0.5925\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7523 - accuracy: 0.6191 - val_loss: 0.8447 - val_accuracy: 0.5822\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7499 - accuracy: 0.6515 - val_loss: 0.8505 - val_accuracy: 0.5616\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8072 - accuracy: 0.5926 - val_loss: 1.2835 - val_accuracy: 0.5342\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8504 - accuracy: 0.6044 - val_loss: 0.8672 - val_accuracy: 0.5719\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7446 - accuracy: 0.6368 - val_loss: 0.9106 - val_accuracy: 0.5616\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7357 - accuracy: 0.6382 - val_loss: 0.8459 - val_accuracy: 0.5719\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7519 - accuracy: 0.6324 - val_loss: 0.8497 - val_accuracy: 0.5822\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7475 - accuracy: 0.6515 - val_loss: 0.8100 - val_accuracy: 0.5856\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7408 - accuracy: 0.6147 - val_loss: 0.9471 - val_accuracy: 0.5890\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.7814 - accuracy: 0.6397 - val_loss: 0.9810 - val_accuracy: 0.5582\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7822 - accuracy: 0.6412 - val_loss: 0.9169 - val_accuracy: 0.5651\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7789 - accuracy: 0.6132 - val_loss: 0.8848 - val_accuracy: 0.5651\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7165 - accuracy: 0.6647 - val_loss: 0.9157 - val_accuracy: 0.6096\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7224 - accuracy: 0.6500 - val_loss: 0.8200 - val_accuracy: 0.6267\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7363 - accuracy: 0.6412 - val_loss: 0.9487 - val_accuracy: 0.6096\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7349 - accuracy: 0.6515 - val_loss: 0.8642 - val_accuracy: 0.6438\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7131 - accuracy: 0.6588 - val_loss: 0.8387 - val_accuracy: 0.5856\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6850 - accuracy: 0.6765 - val_loss: 0.8449 - val_accuracy: 0.6233\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7114 - accuracy: 0.6588 - val_loss: 0.9303 - val_accuracy: 0.5890\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6813 - accuracy: 0.6647 - val_loss: 0.8297 - val_accuracy: 0.6027\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6849 - accuracy: 0.6838 - val_loss: 0.8962 - val_accuracy: 0.6370\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.7074 - val_loss: 0.9443 - val_accuracy: 0.6062\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7024 - accuracy: 0.6559 - val_loss: 1.0208 - val_accuracy: 0.5308\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6740 - accuracy: 0.6926 - val_loss: 0.8868 - val_accuracy: 0.6027\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6696 - accuracy: 0.6676 - val_loss: 0.9009 - val_accuracy: 0.5856\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6990 - accuracy: 0.6647 - val_loss: 0.8977 - val_accuracy: 0.5890\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6623 - accuracy: 0.6735 - val_loss: 0.8852 - val_accuracy: 0.6610\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.6882 - val_loss: 0.9444 - val_accuracy: 0.6301\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6361 - accuracy: 0.7132 - val_loss: 1.0006 - val_accuracy: 0.6301\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6434 - accuracy: 0.6985 - val_loss: 0.9178 - val_accuracy: 0.6370\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6682 - accuracy: 0.6853 - val_loss: 1.0287 - val_accuracy: 0.5959\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7338 - accuracy: 0.6588 - val_loss: 0.9054 - val_accuracy: 0.6267\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9197 - accuracy: 0.5147 - val_loss: 1.0967 - val_accuracy: 0.4384\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8702 - accuracy: 0.5456 - val_loss: 1.1438 - val_accuracy: 0.4384\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8496 - accuracy: 0.5309 - val_loss: 1.0594 - val_accuracy: 0.5171\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8274 - accuracy: 0.5412 - val_loss: 1.0950 - val_accuracy: 0.5342\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8435 - accuracy: 0.5456 - val_loss: 1.1238 - val_accuracy: 0.4521\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8651 - accuracy: 0.5529 - val_loss: 1.0557 - val_accuracy: 0.4212\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8945 - accuracy: 0.5559 - val_loss: 1.4837 - val_accuracy: 0.4863\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9553 - accuracy: 0.5515 - val_loss: 1.0340 - val_accuracy: 0.5205\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9406 - accuracy: 0.5176 - val_loss: 0.9554 - val_accuracy: 0.4589\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9711 - accuracy: 0.4706 - val_loss: 0.9813 - val_accuracy: 0.5171\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9541 - accuracy: 0.5044 - val_loss: 1.0015 - val_accuracy: 0.5103\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9329 - accuracy: 0.4853 - val_loss: 1.0354 - val_accuracy: 0.4212\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8739 - accuracy: 0.5309 - val_loss: 0.9776 - val_accuracy: 0.5103\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8644 - accuracy: 0.5279 - val_loss: 0.9100 - val_accuracy: 0.5240\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8330 - accuracy: 0.5838 - val_loss: 0.9046 - val_accuracy: 0.5240\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8072 - accuracy: 0.6132 - val_loss: 0.9484 - val_accuracy: 0.4726\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8243 - accuracy: 0.5676 - val_loss: 0.9775 - val_accuracy: 0.5103\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8218 - accuracy: 0.5662 - val_loss: 0.9683 - val_accuracy: 0.4932\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, np.ravel(y_train), \n",
    "                    validation_data=(X_test, np.ravel(y_test)), \n",
    "                    epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9682949781417847, 0.4931506812572479]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, np.ravel(y_test), verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.97\n",
      "accuracy: 49.32%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random - uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=14)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=120,\n",
    "    dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.05],\n",
    "    'model__hidden_layer_sizes': [(70,)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[10],\n",
    "    'epochs':[10],\n",
    "    'optimizer':[adam]\n",
    "}\n",
    "keras_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 8 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 5 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 941us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 7 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 6 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 990us/step\n",
      "14/14 [==============================] - 0s 991us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 7 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 8 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_DNN_uniform = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 980us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN-60,50,40</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-120</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls70</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-150</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0              rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0              grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0                         lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                   rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                           dtree  0.994595   0.993056  1.000000  0.996516\n",
       "0                  rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0                 grid_poly_dtree  0.994565   0.993007  1.000000  0.996491\n",
       "0                     NN-60,50,40  0.994565   0.993007  1.000000  0.996491\n",
       "0  random-DNN-uniform-e10-hls-120  0.653543   0.812500  0.750000  0.780000\n",
       "0     random-DNN-normal-e10-hls70  0.614754   0.788889  0.717172  0.751323\n",
       "0  random-DNN-uniform-e10-hls-150  0.716418   0.846154  0.800000  0.822430"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = random_DNN_uniform.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"random-DNN-uniform-e10-hls-150\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=14)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotNormal(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    ann.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=120,\n",
    "    dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.05],\n",
    "    'model__hidden_layer_sizes': [(70,)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[10],\n",
    "    'epochs':[10],\n",
    "    'optimizer':[adam]\n",
    "}\n",
    "keras_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 7 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 6 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 6 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 5 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n",
      "14/14 [==============================] - 0s 945us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 4 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 258, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 68, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1054, in predict\n",
      "    y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\scikeras\\utils\\transformers.py\", line 265, in inverse_transform\n",
      "    class_predictions = self._final_encoder.inverse_transform(class_predictions)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 113, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)  # noqa\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 675, in inverse_transform\n",
      "    Xt = transform.inverse_transform(Xt)\n",
      "  File \"c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 990, in inverse_transform\n",
      "    X_tr[:, i] = self.categories_[i][labels]\n",
      "IndexError: index 9 is out of bounds for axis 0 with size 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\mukes\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_DNN_normal = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 918us/step\n"
     ]
    }
   ],
   "source": [
    "model_preds = rand_DNN_normal.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"random-DNN-normal-e10-hls120\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN-60,50,40</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-120</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls70</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0              rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0              grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0                         lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                   rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                           dtree  0.994595   0.993056  1.000000  0.996516\n",
       "0                  rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0                 grid_poly_dtree  0.994565   0.993007  1.000000  0.996491\n",
       "0                     NN-60,50,40  0.994565   0.993007  1.000000  0.996491\n",
       "0  random-DNN-uniform-e10-hls-120  0.653543   0.812500  0.750000  0.780000\n",
       "0     random-DNN-normal-e10-hls70  0.614754   0.788889  0.717172  0.751323"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls70</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-120</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls120</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-150</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN-60,50,40</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0     random-DNN-normal-e10-hls70  0.614754   0.788889  0.717172  0.751323\n",
       "0  random-DNN-uniform-e10-hls-120  0.653543   0.812500  0.750000  0.780000\n",
       "0                         lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                   rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0              rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0              grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0    random-DNN-normal-e10-hls120  0.716535   0.841584  0.809524  0.825243\n",
       "0  random-DNN-uniform-e10-hls-150  0.716418   0.846154  0.800000  0.822430\n",
       "0                  rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0                 grid_poly_dtree  0.994565   0.993007  1.000000  0.996491\n",
       "0                     NN-60,50,40  0.994565   0.993007  1.000000  0.996491\n",
       "0                           dtree  0.994595   0.993056  1.000000  0.996516"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by='Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls70</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-120</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-uniform-e10-hls-150</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random-DNN-normal-e10-hls120</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.841584</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.825243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.814433</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.887640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.903846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_search_log_l2</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_search_log_l1</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_tree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_dtree</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN-60,50,40</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0     random-DNN-normal-e10-hls70  0.614754   0.788889  0.717172  0.751323\n",
       "0  random-DNN-uniform-e10-hls-120  0.653543   0.812500  0.750000  0.780000\n",
       "0  random-DNN-uniform-e10-hls-150  0.716418   0.846154  0.800000  0.822430\n",
       "0    random-DNN-normal-e10-hls120  0.716535   0.841584  0.809524  0.825243\n",
       "0                         lin svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                   rand_poly_svm  0.797980   0.814433  0.975309  0.887640\n",
       "0                default logistic  0.827586   0.839286  0.979167  0.903846\n",
       "0              rand_search_log_l2  0.827586   0.840708  0.979381  0.904762\n",
       "0              grid_search_log_l1  0.827586   0.840708  0.979381  0.904762\n",
       "0                  rand_poly_tree  0.994565   0.993007  1.000000  0.996491\n",
       "0                 grid_poly_dtree  0.994565   0.993007  1.000000  0.996491\n",
       "0                     NN-60,50,40  0.994565   0.993007  1.000000  0.996491\n",
       "0                           dtree  0.994595   0.993056  1.000000  0.996516"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by='Accuracy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can say that when accuracy scores are compared with different models dtree is the best model among them and also the precision is more for dtree model. I have observed that when the data set is trained with Deep nueral network, changes in epoch and hidden layer size had a significant impact in both cases of uniform and normal distribution of weights. Increasing the hidden layer size has led to increase in the accuracy and little comparable change in precision. When compared MLP and Keras model with other models Dtree is best performing model in all kinds of metrics."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Class08b-decision_tree_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
